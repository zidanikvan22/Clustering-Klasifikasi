# -*- coding: utf-8 -*-
"""[Klasifikasi]_Submission_Akhir_BMLP_Zidan_Muhammad_Ikvan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QoCx1sajKvMyVEs1RMDidX7Jc4F0DvBP

## **Nama** : Zidan Muhammad Ikvan
## **Cohort ID** : MC404D5Y0059
## **Email** : zidanikvan@gmail.com

# **1. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report
from xgboost import XGBClassifier

"""# **2. Memuat Dataset dari Hasil Clustering**

Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

airs = pd.read_csv("/content/air_selected.csv")

airs

airs.info()

airs.describe(include="all")

"""# **3. Data Splitting**

Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

# Pisahkan fitur (X) dan target (y)
X = airs.drop(['Cluster', 'cc1_miles'], axis=1)  # Menyingkirkan agar tidak overfitting
y = airs['Cluster']  # Target

# Bagi data menjadi training set (70%) dan testing set (30%) dengan stratify
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42,  # Untuk reproducibility
    stratify=y  # Pertahankan distribusi kelas
)

# Cek distribusi kelas dan ukuran dataset
print("\nDistribusi Kelas di Dataset Asli:")
print(y.value_counts(normalize=True))

print("\nDistribusi Kelas di Training Set:")
print(y_train.value_counts(normalize=True))

print("\nDistribusi Kelas di Testing Set:")
print(y_test.value_counts(normalize=True))

print("\nJumlah Data Training:", X_train.shape[0])
print("Jumlah Data Testing:", X_test.shape[0])

"""# **4. Membangun Model Klasifikasi**

## **a. Membangun Model Klasifikasi**

Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).
2. Latih model menggunakan data latih.

Tulis narasi atau penjelasan algoritma yang Anda gunakan.

Beberapa alasan saya memilih random forest dan XGBoost sebagai algoritma klasifikasi:
1. Kemampuan menangani data tidak seimbang
  - Dataset memiliki distribusi kelas tidak seimbang (64% vs 36%).
2. Ketahanan terhadap overfitting
3. Fleksibilitas untuk tuning, Keduanya memiliki banyak hyperparameter yang bisa dioptimasi
"""

# latih model pertama: Random Forest
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=5,
    random_state=42,
    class_weight='balanced'  # Handle class imbalance
)
rf_model.fit(X_train, y_train)

# latih model kedua: XGBoost
xgb_model = XGBClassifier(
    n_estimators=100,
    max_depth=3,
    random_state=42,
    scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1])  # Handle imbalance
)
xgb_model.fit(X_train, y_train)

# Prediksi pada data latih
y_train_pred_rf = rf_model.predict(X_train)  # Random Forest
y_train_pred_xgb = xgb_model.predict(X_train)  # XGBoost

# Fungsi untuk menampilkan metrik yang sudah diperbaiki
def print_metrics(model_name, y_true, y_pred):
    print(f"\nEvaluasi {model_name} pada Data Latih:")
    print(classification_report(y_true, y_pred, digits=4))
    print(f"F1-Score: {f1_score(y_true, y_pred):.4f}")
    print(f"Recall: {recall_score(y_true, y_pred):.4f}")
    print(f"Precision: {precision_score(y_true, y_pred):.4f}")
    print(f"Accuracy: {accuracy_score(y_true, y_pred):.4f}")

# Tampilkan hasil untuk kedua model
print_metrics("Random Forest", y_train, y_train_pred_rf)
print_metrics("XGBoost", y_train, y_train_pred_xgb)

"""## **b. Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Lakukan prediksi menggunakan data uji.
2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).
3. Buat confusion matrix untuk melihat detail prediksi benar dan salah.

Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.
"""

# Prediksi dengan kedua model
y_pred_rf = rf_model.predict(X_test)  # Random Forest
y_pred_xgb = xgb_model.predict(X_test)  # XGBoost

# Fungsi untuk menghitung semua metrik
def evaluate_model(model_name, y_true, y_pred):
    metrics = {
        'Accuracy': accuracy_score(y_true, y_pred),
        'F1-Score': f1_score(y_true, y_pred),
        'Precision': precision_score(y_true, y_pred),
        'Recall': recall_score(y_true, y_pred)
    }
    return pd.DataFrame(metrics, index=[model_name])

# Gabungkan hasil evaluasi kedua model
results = pd.concat([
    evaluate_model("Random Forest", y_test, y_pred_rf),
    evaluate_model("XGBoost", y_test, y_pred_xgb)
])

print("Perbandingan Metrik:")
print(results.round(2))

def plot_confusion_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Prediksi 0', 'Prediksi 1'],
                yticklabels=['Aktual 0', 'Aktual 1'])
    plt.title(title)
    plt.ylabel('Aktual')
    plt.xlabel('Prediksi')
    plt.show()

# Plot untuk kedua model
plot_confusion_matrix(y_test, y_pred_rf, "Random Forest")
plot_confusion_matrix(y_test, y_pred_xgb, "XGBoost")

print("\nLaporan Klasifikasi Random Forest:")
print(classification_report(y_test, y_pred_rf))

print("\nLaporan Klasifikasi XGBoost:")
print(classification_report(y_test, y_pred_xgb))

"""## **c. Tuning Model Klasifikasi (Optional)**

Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik
"""

# Tuning untuk XGBoost
param_grid = {
    'max_depth': [3, 5],
    'learning_rate': [0.01, 0.1]
}
grid = GridSearchCV(xgb_model, param_grid, cv=5, scoring='f1')
grid.fit(X_train, y_train)
print("Parameter Terbaik XGBoost:", grid.best_params_)

"""## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**

Berikut adalah rekomendasi tahapannya.
1. Gunakan model dengan hyperparameter terbaik.
2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa.
"""

# Gunakan model terbaik dari GridSearchCV untuk prediksi
best_model = grid.best_estimator_
y_pred_tuned = best_model.predict(X_test)

# Hitung metrik
accuracy = accuracy_score(y_test, y_pred_tuned)
f1 = f1_score(y_test, y_pred_tuned)

print("Hasil Setelah Tuning:")
print(f"Best Parameters: {grid.best_params_}")
print(f"Accuracy: {accuracy:.4f}")
print(f"F1-Score: {f1:.4f}")

# Prediksi dengan model default (sebelum tuning)
y_pred_default = xgb_model.predict(X_test)

# Hitung metrik default
accuracy_default = accuracy_score(y_test, y_pred_default)
f1_default = f1_score(y_test, y_pred_default)

print("\nPerbandingan dengan Model Default:")
print(f"Accuracy (Default): {accuracy_default:.4f} → Tuned: {accuracy:.4f}")
print(f"F1-Score (Default): {f1_default:.4f} → Tuned: {f1:.4f}")

"""## **e. Analisis Hasil Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).
Hasil:
  - Akurasi: Naik 0.36% (0.9408 → 0.9442)
  - F1-Score: Naik 0.54% (0.9189 → 0.9243)
  - Tuning berhasil meningkatkan performa, meskipun peningkatan tergolong kecil.

2. Identifikasi kelemahan model, seperti:
  - Precision atau Recall rendah untuk kelas tertentu.
    - Kelas Minoritas (Cluster 1) perlu diperhatikan karena distribusi data 64:36.
    - Recall (0.94) > Precision (0.90) pada XGBoost → Model cenderung lebih agresif memprediksi kelas positif (mungkin masih ada sedikit leakage tersisa).
  - Apakah model mengalami overfittng atau underfitting?
    - Tidak ada indikasi overfitting karena selisih akurasi training-testing <2%
    - Tidak underfitting karena metrik sudah baik (>92%).
    
3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan.
  - Memperbanyak sampel kelas minoritas (Cluster 1) jika memungkinkan.
  - data baru tidak mengandung leakage
"""